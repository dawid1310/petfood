{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from utils import resize_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('ow_niem.jpg')\n",
    "im = cv2.resize(im, (224,224))\n",
    "plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = 'db/low-resolution/1043-n000001-Shiba_Dog/n101045.jpeg'\n",
    "# ff = 'db/low-resolution/1043-n000001-Shiba_Dog/n101040.jpeg'\n",
    "ff = 'ow_niem.jpg'\n",
    "im = cv2.imread(ff)\n",
    "print(type(im))\n",
    "print(im.shape)\n",
    "im = resize_im(im, 224, True)\n",
    "cv2.imwrite('aaa.png', im)\n",
    "print(im.shape)\n",
    "plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "# cv2.imshow('1',im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_from_folder(folder_name):\n",
    "    return folder_name[folder_name.rindex('-')+1:].replace('_', ' ').capitalize()\n",
    "\n",
    "def get_class_from_path(fname):\n",
    "    s = fname[fname.rindex('-')+1:].replace('_', ' ').capitalize()\n",
    "    return s[:s.index('/')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_im_path = 'db/low-resolution'\n",
    "dog_im_path_annot = 'db/Low-Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert files with train file list\n",
    "def convert_list_of_images(in_fname, out_fname):\n",
    "    f = open(in_fname, 'r')\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    f = open(out_fname, 'w')\n",
    "    for line in lines:\n",
    "        f.write(line.strip()[3:]+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain = 'db/train.lst'\n",
    "fval = 'db/validation.lst'\n",
    "\n",
    "convert_list_of_images(ftrain, 'train_images.txt')\n",
    "convert_list_of_images(fval, 'val_images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogImageGeneratorSeq(Sequence):\n",
    "    def __init__(self, path, fimlist, pathannot=None, cls_names = None, imsize = 224, imloop=False, batch_size=4, shuffle = True, to_fit = True, even_cls=False, prob_flip=0, prob_rot=0, rot_max = 20):\n",
    "        self.path = path\n",
    "        self.pathannot = pathannot\n",
    "        self.fimlist = fimlist\n",
    "        self.imsize = imsize\n",
    "        self.imloop = imloop\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.to_fit = to_fit\n",
    "        self.even_cls = even_cls\n",
    "        self.prob_flip = prob_flip\n",
    "        self.prob_rot = prob_rot\n",
    "        self.rot_max = rot_max\n",
    "        f = open(self.fimlist, 'r')\n",
    "        self.ims = [x.strip() for x in f.readlines()]\n",
    "        f.close()\n",
    "        if cls_names:\n",
    "            self.cls_names = cls_names\n",
    "        else:\n",
    "            cls_names = set()\n",
    "            for x in self.ims:\n",
    "                cls_names.add(get_class_from_path(x))\n",
    "            cls_names = list(cls_names)\n",
    "            cls_names.sort()\n",
    "            self.cls_names = cls_names\n",
    "        self.cls = []\n",
    "        for x in self.ims:\n",
    "            self.cls.append(self.cls_names.index(get_class_from_path(x)))\n",
    "        self.indxs = np.arange(len(self.ims))\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.ims) / self.batch_size))\n",
    "    def __getitem__(self, idx):\n",
    "        if self.even_cls:\n",
    "            return self.__getitem_even(idx)\n",
    "        else:\n",
    "            return self.__getitem__linear(idx)\n",
    "    def __getitem__linear(self, idx):\n",
    "        indxs_tmp = self.indxs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        tmpX = [self._get_sample_(self.ims[i]) for i in indxs_tmp]\n",
    "        tmpX = np.array(tmpX)\n",
    "        tmpX = tmpX.astype(np.float32)/255\n",
    "        tmpY = to_categorical([self.cls[i] for i in indxs_tmp], num_classes=len(self.cls_names))\n",
    "        if self.to_fit:\n",
    "            return tmpX, tmpY\n",
    "        else:\n",
    "            return tmpX            \n",
    "    def __getitem_even(self, idx):\n",
    "        tmpX = []\n",
    "        tmpY = []\n",
    "        for i in range(self.batch_size):\n",
    "            ii = np.random.randint(len(self.cls_names))\n",
    "            cims = [self.ims[idx] for idx in range(len(self.ims)) if self.cls[idx]==ii]\n",
    "            imfile = cims[np.random.randint(len(cims))]\n",
    "            tmpX.append(self._get_sample_(imfile))\n",
    "            tmpY.append(ii)\n",
    "        tmpX = np.array(tmpX)\n",
    "        tmpX = tmpX.astype(np.float32)/255\n",
    "        tmpY = to_categorical(tmpY, num_classes=len(self.cls_names))\n",
    "        if self.to_fit:\n",
    "            return tmpX, tmpY\n",
    "        else:\n",
    "            return tmpX\n",
    "    def on_epoch_end(self):\n",
    "        self.indxs = np.arange(len(self.ims))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indxs)\n",
    "    def _get_sample_(self, impath):\n",
    "        im = cv2.imread(self.path + '/' + impath)\n",
    "        if self.pathannot: #get body annotation\n",
    "            fxml = self.pathannot + '/' + impath + '.xml'\n",
    "            tree = ET.parse(fxml)\n",
    "            root = tree.getroot()\n",
    "            box = root.find('object').find('bodybndbox')\n",
    "            xmin, xmax, ymin, ymax = box.find('xmin').text, box.find('xmax').text, box.find('ymin').text, box.find('ymax').text\n",
    "            xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "            im = im[ymin:ymax,xmin:xmax,:]\n",
    "        if self.prob_flip > 0 and np.random.rand() < self.prob_flip:\n",
    "            im = cv2.flip(im, [-1, 0, 1][np.random.randint(3)])\n",
    "        if self.prob_rot > 0 and np.random.rand() < self.prob_rot:\n",
    "            M = cv2.getRotationMatrix2D((im.shape[1]/2,im.shape[0]/2),-self.rot_max+np.random.rand()*2*self.rot_max,1)\n",
    "            im = cv2.warpAffine(im, M, (im.shape[1], im.shape[0])) \n",
    "        im = resize_im(im, self.imsize, self.imloop)\n",
    "        return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen = DogImageGeneratorSeq(dog_im_path, 'train_images.txt', pathannot=dog_im_path_annot, imloop=True, batch_size=4,\n",
    "                            prob_flip=1, prob_rot=1, rot_max=20)\n",
    "x, y = dgen[0]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(x[0], cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen = DogImageGeneratorSeq(dog_im_path, 'train_images.txt', pathannot=dog_im_path_annot, cls_names = None, imsize = 224, imloop=True, batch_size=128, shuffle = True, to_fit = True, even_cls=True, prob_flip=0.5, prob_rot=0, rot_max = 20)\n",
    "val_gen = DogImageGeneratorSeq(dog_im_path, 'val_images.txt', pathannot=None, cls_names = tr_gen.cls_names, imsize = 224, imloop=True, batch_size=128, shuffle = True, to_fit = True, even_cls=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(tr_gen.cls_names)\n",
    "\n",
    "imsize = tr_gen.imsize\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, input_shape=(imsize, imsize, 3), activation='relu', data_format='channels_last'))\n",
    "model.add(Conv2D(32, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(Conv2D(32, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(Conv2D(32, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(Conv2D(32, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model = load_model('_model_.hdf5')\n",
    "model.summary()\n",
    "\n",
    "logger = keras.callbacks.ModelCheckpoint('_model_.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit_generator(generator=tr_gen, validation_data=val_gen, epochs=100, verbose=1, callbacks=[logger], use_multiprocessing=False, workers=6)\n",
    "print(history)\n",
    "\n",
    "scores = model.evaluate(val_gen, verbose=1)\n",
    "print(\"Validation error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "#Wczytanie najlepszego modelu z pliku\n",
    "model2 = load_model('_model_.hdf5')\n",
    "# model2 = load_model('_model_.hdf5', compile=False)\n",
    "# model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "scores2 = model2.evaluate(val_gen, verbose=1)\n",
    "print('model z pliku:')\n",
    "print(\"validation error: %.2f%%\" % (100-scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RESNET\n",
    "tr_gen = DogImageGeneratorSeq(dog_im_path, 'train_images.txt', pathannot=dog_im_path_annot, cls_names = None, imsize = 224, imloop=True, batch_size=32, shuffle = True, to_fit = True, even_cls=True, prob_flip=0.5, prob_rot=0.5, rot_max = 20)\n",
    "val_gen = DogImageGeneratorSeq(dog_im_path, 'val_images.txt', pathannot=None, cls_names = tr_gen.cls_names, imsize = 224, imloop=True, batch_size=32, shuffle = True, to_fit = True, even_cls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET experiments\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3) )\n",
    "# base_model.summary()\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(130, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# freeze\n",
    "# for lay in base_model.layers:\n",
    "#     lay.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "logger = keras.callbacks.ModelCheckpoint('_model_.hdf5', monitor='val_accuracy', verbose=0, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(generator=tr_gen, validation_data=val_gen, epochs=2, verbose=1, callbacks=[logger], use_multiprocessing=False, workers=6)\n",
    "print(history)\n",
    "\n",
    "scores = model.evaluate(val_gen, verbose=1)\n",
    "print(\"Validation error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "#Wczytanie najlepszego modelu z pliku\n",
    "model2 = load_model('_model_.hdf5')\n",
    "# model2 = load_model('_model_.hdf5', compile=False)\n",
    "# model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "scores2 = model2.evaluate(val_gen, verbose=1)\n",
    "print('model z pliku:')\n",
    "print(\"validation error: %.2f%%\" % (100-scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resneet continue training\n",
    "history = model.fit_generator(generator=tr_gen, validation_data=val_gen, epochs=48, verbose=1, callbacks=[logger], use_multiprocessing=False, workers=6)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('_model_.hdf5')\n",
    "scores_test = model2.evaluate(val_gen, verbose=2)\n",
    "print(\"Test error: %.2f%%\" % (100-scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen2 = DogImageGeneratorSeq(dog_im_path, 'val_images.txt', pathannot=dog_im_path_annot, cls_names = tr_gen.cls_names, imsize = 224, imloop=True, batch_size=64, shuffle = True, to_fit = True, even_cls=False)\n",
    "model2 = load_model('_model_.hdf5')\n",
    "scores_test = model2.evaluate(val_gen2, verbose=2)\n",
    "print(\"Test error: %.2f%%\" % (100-scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen2 = DogImageGeneratorSeq(dog_im_path, 'train_images.txt', pathannot=dog_im_path_annot, cls_names = tr_gen.cls_names, imsize = 224, imloop=True, batch_size=64, shuffle = True, to_fit = True, even_cls=False)\n",
    "model2 = load_model('_model_.hdf5')\n",
    "scores_test = model2.evaluate(tr_gen2, verbose=2)\n",
    "print(\"Test error: %.2f%%\" % (100-scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predykcja dla konkretnego obrazu\n",
    "impath = 'images/bullterrier.jpg'\n",
    "size = 224\n",
    "im = cv2.imread(impath)\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "im = resize_im(im, size, True)\n",
    "# plt.figure()\n",
    "# plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "print(im.shape)\n",
    "\n",
    "import numpy as np\n",
    "im = np.expand_dims(im, axis=0)\n",
    "preds = model2.predict(im).flatten()\n",
    "# print(type(preds))\n",
    "# print(preds)\n",
    "print(preds.shape)\n",
    "# print(preds)\n",
    "indxs = preds.argsort()[::-1]\n",
    "print(indxs[:10])\n",
    "print(preds[indxs[:10]])\n",
    "cls_names = np.array(val_gen2.cls_names)\n",
    "print(cls_names[indxs[:10]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
